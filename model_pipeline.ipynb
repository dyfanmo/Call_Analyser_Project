{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "71a5e00d-dbef-4b7e-9953-6cd6297a0f19",
   "metadata": {},
   "outputs": [],
   "source": [
    "import openai\n",
    "from models.speech.model import transcribe_audio \n",
    "from models.diarisation.model import get_speaker_segments\n",
    "from models.disclaimer.model import disclaimer_verifier\n",
    "from models.disclaimer.constants import disclaimer_text\n",
    "from models.sentiment.model import return_call_sentiment\n",
    "from models.summariser.gpt_model import get_gpt_call_summary\n",
    "from models.gpt_prompts import call_summary_instructions\n",
    "from preprocessing.utils import convert_audio_to_wav, is_audio_mono, convert_stereo_audio_to_mono, load_text_file"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22f40014-f2dc-414b-a2f5-18483d19611b",
   "metadata": {},
   "source": [
    "### Audio Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b288615-ee6e-4101-89d2-cd36aba58f7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_path = \"data/Call-1-Example.mp3\"\n",
    "clean_data_dir = \"cleaned_data/\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4352fc1-251f-4575-9bf9-ea8cd81a449e",
   "metadata": {},
   "source": [
    "Analysis will not work on MP3 files, so the audio data is converted to a WAV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dd63674f-9b86-48a8-a534-e9b59e8791ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_audio_path = convert_audio_to_wav(audio_path, clean_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87286794-272f-4889-a70d-fe929a2140ab",
   "metadata": {},
   "source": [
    "Using stereo audio will result in failure during speaker diarization, so it needs to be converted to mono."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cb7397e3-5bc7-4ffa-afcc-b13ed226a57a",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not is_audio_mono(new_audio_path):\n",
    "    new_audio_path = convert_stereo_audio_to_mono(new_audio_path, clean_data_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea315da-4133-43ad-aaef-609063a9b175",
   "metadata": {},
   "source": [
    "### Speach Recognition\n",
    "\n",
    "* Utilize OpenAI's transcription service to transcribe the audio.\n",
    "* Employ Speechbrain's speaker diarization module to identify speakers.\n",
    "\n",
    "The num_speakers argument is required for speaker diarization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "eff8aec6-8842-42fe-bde6-1aa47fe6d6d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = transcribe_audio(new_audio_path, num_speakers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c53e3e4a-5fa5-4737-a9c8-a4ef274f2f36",
   "metadata": {},
   "source": [
    "### Speaker Diarization "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fb7dc5d-efaf-4bb8-ab2b-f6ebfe6fbf30",
   "metadata": {},
   "source": [
    "It is now possible to organize speech transcription based on the speaker's identity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b2bd8a7c-2de2-4259-a450-9baf4986dd43",
   "metadata": {},
   "outputs": [],
   "source": [
    "speaker_segments_dict = get_speaker_segments(results[\"segments\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "78b49bd2-4d4e-4c64-a6e0-355c08724e6e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Hi Anna, my name is Bob.  I'm calling because I've been tracking a parcel that was supposed to be delivered to me three days ago.  But the status hasn't updated since it was out of delivery.  Can you help me with that?\",\n",
       " 'start': 25.52,\n",
       " 'end': 40.04,\n",
       " 'segment_num': 4}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_segments_dict[\"SPEAKER 2\"][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "64163bb5-fc6b-48ee-b2c7-6ca83d3e30f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'Good morning, thank you for calling the Ghost Office, the most-isperated postal service.  My name is Anna, how can I assist you today?  Before we proceed, I need to inform you that this call is being recorded.  We may contact you in the future to offer future products and services.  You can always have the option to withdraw from receiving this contact from us.  Now, how can I help you today?',\n",
       " 'start': 0.0,\n",
       " 'end': 25.04,\n",
       " 'segment_num': 6}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_segments_dict[\"SPEAKER 1\"][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "447cfbcd-c6ff-40d5-a8d7-bb7490b80156",
   "metadata": {},
   "source": [
    "### Disclaimer Verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "198ea856-6ae4-46c6-a710-9d81b77cc26e",
   "metadata": {},
   "source": [
    "To determine which segment to compare with the disclaimer text, I executed a for loop on both speakers' segments and computed similarity scores for each segment. Then, only the maximum score is returned.\n",
    "\n",
    "Disclaimer verification rules:\n",
    "1. If the similarity score is less than 50%, 'false' will be returned.\n",
    "2. If the speaker utters the disclaimer after 45 seconds, 'false' will be returned.\n",
    "3. If the speaker utters the disclaimer after reaching the third segment in the speaker_segments_dict, 'false' will be returned.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e431df07-65c0-4959-bbf8-d85ee65d4914",
   "metadata": {},
   "source": [
    "In this example, I am comparing the following two passages of text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6d8650f2-ae55-4f20-87f3-fb4eb463bef4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I need to inform you that this call is recorded. We may contact you in the future to offer further products and services. You always have the option to withdraw from receiving this contact from us'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disclaimer_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec280f09-fd05-4664-9e67-71296fd16fea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Good morning, thank you for calling the Ghost Office, the most-isperated postal service.  My name is Anna, how can I assist you today?  Before we proceed, I need to inform you that this call is being recorded.  We may contact you in the future to offer future products and services.  You can always have the option to withdraw from receiving this contact from us.  Now, how can I help you today?'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "speaker_segments_dict[\"SPEAKER 1\"][0][\"text\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "c14f6511-ebb5-457f-8f45-fd840ce72642",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disclaimer_verifier(speaker_segments_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3333527-773a-43e1-9294-d8542d8ca03c",
   "metadata": {},
   "source": [
    "### Sentiment Analysis\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d788edc5-79d6-4dc7-a459-ddb3ed07f02e",
   "metadata": {},
   "source": [
    "\n",
    "A sentiment analysis model is utilized to determine the overall tone of the conversation. A custom neutral threshold is employed to specify the strictness of this model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "aea74533-687f-49ab-a581-02d655e69d7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No model was supplied, defaulted to distilbert/distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert/distilbert-base-uncased-finetuned-sst-2-english).\n",
      "Using a pipeline without specifying a model name and revision in production is not recommended.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_call_sentiment(results[\"text\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ba648ec-6e10-499f-845a-0679fcfd060e",
   "metadata": {},
   "source": [
    "### Call Text Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "798d1acf-be05-443c-a884-2768c463cac6",
   "metadata": {},
   "source": [
    "GPT 3.5 test example. I copied and pasted the full prompt into ChatGPT. \n",
    "\n",
    "The full prompt will include a list of instructions and a string version of the speaker segment dict.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0da03e0-49db-4b2c-bc01-796301bbc06a",
   "metadata": {},
   "source": [
    "A list of of instructions is given to the gpt model before the output\n",
    "\n",
    "GPT Instructions:\n",
    "\n",
    "* \"You will be asked to summarised information about a phone call.\"\n",
    "* \" Make sure to include bullet points on what each person said and bullet points on action items\"\n",
    "\n",
    "Rules to follow:\n",
    "* \" concise and informative\"\n",
    "* \" capturing key points and action items.\" \n",
    "* \" a format that is easily understandable and highlights important aspects of the conversation.\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c76ee18b-cbf8-4ed6-85fa-deb7462d8f51",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = openai.OpenAI(api_key=load_text_file(\"openai_key.txt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5957a083-5f82-46a9-b7c9-c483efc382df",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = get_gpt_call_summary(client, str(speaker_segments_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "32208eb2-730a-4af3-be65-c9e8d2be4e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**Summary:**\n",
      "- **Speaker 1: Anna**\n",
      "    - \"Good morning, thank you for calling the Ghost Office. How can I assist you today?\"\n",
      "    - Requested Bob for tracking number to resolve parcel issue.\n",
      "    - Informed Bob about delay in delivery due to unexpected reroute but assured delivery by tomorrow.\n",
      "    - Offered to sign Bob up for SMS notifications for updates on parcel's journey and delivery time window.\n",
      "    - Concluded call by offering further assistance and looking forward to parcel's delivery tomorrow.\n",
      "\n",
      "- **Speaker 2: Bob**\n",
      "    - Bob called to inquire about a parcel that was supposed to be delivered three days ago but with no status update since out for delivery.\n",
      "    - Provided tracking number GH123456789.\n",
      "    - Expressed relief upon hearing about the delay reason.\n",
      "    - Opted for SMS notifications for updates to avoid missing delivery.\n",
      "    - Expressed gratitude for Anna's assistance and confirmed no further assistance needed.\n",
      "    - Thanked Anna and expressed well wishes.\n",
      "\n",
      "**Action Items:**\n",
      "- Parcel delivery to Bob is confirmed by the end of the day tomorrow.\n",
      "- Bob signed up for SMS notifications for updates on the parcel's journey and specific delivery time window.\n",
      "- Bob to contact Ghost Office for any further assistance in the future.\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b939392d-9c86-4f63-ac39-48d1565861c7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
